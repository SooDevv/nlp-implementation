{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('../../data/ner_dataset.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1048565</th>\n",
       "      <td>NaN</td>\n",
       "      <td>impact</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048566</th>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048567</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Indian</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048568</th>\n",
       "      <td>NaN</td>\n",
       "      <td>forces</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048569</th>\n",
       "      <td>NaN</td>\n",
       "      <td>said</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>NaN</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>NaN</td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>NaN</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>NaN</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sentence #       Word  POS    Tag\n",
       "1048565              NaN     impact   NN      O\n",
       "1048566              NaN          .    .      O\n",
       "1048567  Sentence: 47959     Indian   JJ  B-gpe\n",
       "1048568              NaN     forces  NNS      O\n",
       "1048569              NaN       said  VBD      O\n",
       "1048570              NaN       they  PRP      O\n",
       "1048571              NaN  responded  VBD      O\n",
       "1048572              NaN         to   TO      O\n",
       "1048573              NaN        the   DT      O\n",
       "1048574              NaN     attack   NN      O"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1048565</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>impact</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048566</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048567</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Indian</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048568</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>forces</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048569</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>said</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sentence #       Word  POS    Tag\n",
       "1048565  Sentence: 47958     impact   NN      O\n",
       "1048566  Sentence: 47958          .    .      O\n",
       "1048567  Sentence: 47959     Indian   JJ  B-gpe\n",
       "1048568  Sentence: 47959     forces  NNS      O\n",
       "1048569  Sentence: 47959       said  VBD      O\n",
       "1048570  Sentence: 47959       they  PRP      O\n",
       "1048571  Sentence: 47959  responded  VBD      O\n",
       "1048572  Sentence: 47959         to   TO      O\n",
       "1048573  Sentence: 47959        the   DT      O\n",
       "1048574  Sentence: 47959     attack   NN      O"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(data[\"Word\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35178"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words = len(words); n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data \n",
    "        self.empty = False\n",
    "        \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.data[self.data[\"Sentence #\"] == \"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s[\"Word\"].values.tolist(), s[\"POS\"].values.tolist(), s[\"Tag\"].values.tolist()\n",
    "        except:\n",
    "            self.empty = True\n",
    "            return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent, pos, tag = getter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.']\n",
      "['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP', 'TO', 'VB', 'DT', 'NN', 'IN', 'NNP', 'CC', 'VB', 'DT', 'NN', 'IN', 'JJ', 'NNS', 'IN', 'DT', 'NN', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(sent); print(pos); print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memorization \n",
    "- simple baseline that remember common named entity for every word and predict that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MemoryTagger(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Expects a list of words as X and a list of tags as y.\n",
    "        '''\n",
    "        voc = {}\n",
    "        self.tags = []\n",
    "        for x, t in zip(X, y):\n",
    "            if t not in self.tags:\n",
    "                self.tags.append(t)\n",
    "            if x in voc:\n",
    "                if t in voc[x]:\n",
    "                    voc[x][t] += 1\n",
    "                else:\n",
    "                    voc[x][t] = 1\n",
    "            else:\n",
    "                voc[x] = {t: 1}\n",
    "                \n",
    "        self.memory = {}\n",
    "        for k, d in voc.items():\n",
    "            self.memory[k] = max(d, key=d.get) #word의 tag중에서 가장 많이 나온 tag를 memorization\n",
    "            \n",
    "    def predict(self, X, y=None):\n",
    "        '''\n",
    "        Predict the tag from memory. If word is unkown, predict 'O'\n",
    "        '''\n",
    "        return [self.memory.get(x, 'O') for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = MemoryTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger.fit(sent, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(tagger.predict(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-geo', 'B-gpe']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = data[\"Word\"].values.tolist()\n",
    "tags = data[\"Tag\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cross_val_predict(estimator=MemoryTagger(), X=words, y=tags, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.20      0.05      0.09       402\n",
      "       B-eve       0.54      0.25      0.34       308\n",
      "       B-geo       0.78      0.85      0.81     37644\n",
      "       B-gpe       0.94      0.93      0.94     15870\n",
      "       B-nat       0.42      0.28      0.33       201\n",
      "       B-org       0.67      0.49      0.56     20143\n",
      "       B-per       0.78      0.65      0.71     16990\n",
      "       B-tim       0.87      0.77      0.82     20333\n",
      "       I-art       0.04      0.01      0.01       297\n",
      "       I-eve       0.39      0.12      0.18       253\n",
      "       I-geo       0.73      0.58      0.65      7414\n",
      "       I-gpe       0.62      0.45      0.52       198\n",
      "       I-nat       0.00      0.00      0.00        51\n",
      "       I-org       0.69      0.53      0.60     16784\n",
      "       I-per       0.73      0.65      0.69     17251\n",
      "       I-tim       0.58      0.13      0.21      6528\n",
      "           O       0.97      0.99      0.98    887908\n",
      "\n",
      "    accuracy                           0.95   1048575\n",
      "   macro avg       0.59      0.45      0.50   1048575\n",
      "weighted avg       0.94      0.95      0.94   1048575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_pred=pred, y_true=tags)\n",
    "print(report)\n",
    "# precision quite well. but recall is poor. because we cannot perdict on words we don't know"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple machine learning approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_map(word):\n",
    "    '''Simple feature map.'''\n",
    "    return np.array([word.istitle(), word.islower(), word.isupper(), len(word), word.isdigit(),  word.isalpha()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [feature_map(w) for w in data[\"Word\"].values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 0, 0, 9, 0, 1]),\n",
       " array([0, 1, 0, 2, 0, 1]),\n",
       " array([ 0,  1,  0, 13,  0,  1]),\n",
       " array([0, 1, 0, 4, 0, 1]),\n",
       " array([0, 1, 0, 7, 0, 1]),\n",
       " array([0, 1, 0, 7, 0, 1]),\n",
       " array([1, 0, 0, 6, 0, 1]),\n",
       " array([0, 1, 0, 2, 0, 1]),\n",
       " array([0, 1, 0, 7, 0, 1]),\n",
       " array([0, 1, 0, 3, 0, 1])]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 48s, sys: 22.9 s, total: 16min 11s\n",
      "Wall time: 55.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred = cross_val_predict(RandomForestClassifier(n_estimators=20), X=words, y=tags, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/irteam/anaconda3/envs/py37_tf20/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00       402\n",
      "       B-eve       0.00      0.00      0.00       308\n",
      "       B-geo       0.26      0.80      0.40     37644\n",
      "       B-gpe       0.25      0.04      0.07     15870\n",
      "       B-nat       0.00      0.00      0.00       201\n",
      "       B-org       0.65      0.17      0.27     20143\n",
      "       B-per       0.96      0.20      0.33     16990\n",
      "       B-tim       0.29      0.32      0.30     20333\n",
      "       I-art       0.00      0.00      0.00       297\n",
      "       I-eve       0.00      0.00      0.00       253\n",
      "       I-geo       0.00      0.00      0.00      7414\n",
      "       I-gpe       0.00      0.00      0.00       198\n",
      "       I-nat       0.00      0.00      0.00        51\n",
      "       I-org       0.36      0.03      0.06     16784\n",
      "       I-per       0.47      0.02      0.04     17251\n",
      "       I-tim       0.50      0.06      0.11      6528\n",
      "           O       0.97      0.98      0.97    887908\n",
      "\n",
      "    accuracy                           0.87   1048575\n",
      "   macro avg       0.28      0.15      0.15   1048575\n",
      "weighted avg       0.88      0.87      0.86   1048575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_pred=pred, y_true=tags)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that looks really bad.\\\n",
    "since the features lack a lot of information necessary for the decision.\\\n",
    "So now we enhance our simple features on the one hand by memory and on the other hand by using context information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class FeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.memory_tagger = MemoryTagger()\n",
    "        self.tag_encoder = LabelEncoder()\n",
    "        self.pos_encoder = LabelEncoder()\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y): \n",
    "        '''\n",
    "        X: data[Sentence #, Word, POS, Tag]\n",
    "        y: data['Tag']\n",
    "        '''\n",
    "        words = X[\"Word\"].values.tolist()\n",
    "        self.pos = X[\"POS\"].values.tolist()\n",
    "        tags = X[\"Tag\"].values.tolist()\n",
    "        self.memory_tagger.fit(words, tags)\n",
    "        self.tag_encoder.fit(tags)\n",
    "        self.pos_encoder.fit(self.pos)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        def pos_default(p):\n",
    "            if p in self.pos:\n",
    "                return self.pos_encoder.transform([p])[0]\n",
    "            else:\n",
    "                return -1\n",
    "            \n",
    "        pos = X[\"POS\"].values.tolist()\n",
    "        words = X[\"Word\"].values.tolist()\n",
    "        out = []\n",
    "        for i in range(len(words)):\n",
    "            w = words[i]\n",
    "            p = pos[i]\n",
    "            if i < len(words) - 1:\n",
    "                wp = self.tag_encoder.transform(self.memory_tagger.predict([words[i+1]]))[0]\n",
    "                posp = pos_default(pos[i+1])\n",
    "            else:\n",
    "                wp = self.tag_encoder.transform(['O'])[0]\n",
    "                posp = pos_default(\".\")\n",
    "            if i > 0:\n",
    "                if words[i-1] != \".\":\n",
    "                    wm = self.tag_encoder.transform(self.memory_tagger.predict([words[i-1]]))[0]\n",
    "                    posm = pos_default(\".\")\n",
    "                    \n",
    "                else:\n",
    "                    wm = self.tag_encoder.transform(['O'])[0]\n",
    "                    posm = pos_default(\".\")\n",
    "            \n",
    "            else:\n",
    "                posm = pos_default(\".\")\n",
    "                wm = self.tag_encoder.transform(['O'])[0]\n",
    "            \n",
    "            out.append(np.array([w.istitle(), w.islower(), w.isupper(), len(w), w.isdigit(), w.isalpha(),\n",
    "                                self.tag_encoder.transform(self.memory_tagger.predict([w]))[0],\n",
    "                                pos_default(p), wp, wm, posp, posm]))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35min 17s, sys: 2min 43s, total: 38min 1s\n",
      "Wall time: 31min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred = cross_val_predict(Pipeline([(\"feature_map\", FeatureTransformer()),\n",
    "                                  (\"clf\", RandomForestClassifier(n_estimators=20, n_jobs=3))]),\n",
    "                        X=data, y=tags, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.16      0.07      0.09       402\n",
      "       B-eve       0.41      0.26      0.32       308\n",
      "       B-geo       0.82      0.86      0.84     37644\n",
      "       B-gpe       0.98      0.93      0.95     15870\n",
      "       B-nat       0.22      0.22      0.22       201\n",
      "       B-org       0.71      0.62      0.66     20143\n",
      "       B-per       0.80      0.76      0.78     16990\n",
      "       B-tim       0.88      0.79      0.84     20333\n",
      "       I-art       0.03      0.01      0.02       297\n",
      "       I-eve       0.25      0.12      0.17       253\n",
      "       I-geo       0.78      0.64      0.70      7414\n",
      "       I-gpe       0.77      0.46      0.58       198\n",
      "       I-nat       0.42      0.16      0.23        51\n",
      "       I-org       0.72      0.64      0.68     16784\n",
      "       I-per       0.86      0.72      0.78     17251\n",
      "       I-tim       0.84      0.46      0.60      6528\n",
      "           O       0.98      1.00      0.99    887908\n",
      "\n",
      "    accuracy                           0.96   1048575\n",
      "   macro avg       0.63      0.51      0.56   1048575\n",
      "weighted avg       0.95      0.96      0.95   1048575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_pred=pred, y_true=tags)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
